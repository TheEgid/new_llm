import csv
import json
import time
from pathlib import Path
from typing import Any

import supabase

from core.logger import logger


def _serialize_value(value: Any) -> Any:  # noqa: ANN401
    if isinstance(value, (dict, list)):
        return json.dumps(value, ensure_ascii=False)
    return value


def backup_table_via_api(
    table_name: str,
    output_file: str,
    supabase_client: supabase.Client,
) -> None:
    """
    Creates a safe CSV backup of a Supabase table.
    Guarantees CSV validity for multiline text, JSON and embeddings.
    """
    try:
        logger.info(f"‚è≥ –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–∞–±–ª–∏—Ü—ã {table_name} —á–µ—Ä–µ–∑ API...")

        count_response = (
            supabase_client
            .table(table_name)
            .select("*", count="exact")
            .execute()
        )
        total_rows = count_response.count or 0

        logger.info(f"üìä –¢–∞–±–ª–∏—Ü–∞ '{table_name}' —Å–æ–¥–µ—Ä–∂–∏—Ç {total_rows} —Å—Ç—Ä–æ–∫")

        if total_rows == 0:
            logger.warning("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞. –ë—ç–∫–∞–ø –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
            return

        if input(f"–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –±—ç–∫–∞–ø {total_rows} —Å—Ç—Ä–æ–∫? (y/n): ").lower() != "y":
            logger.info("‚ùå –ë—ç–∫–∞–ø –æ—Ç–º–µ–Ω–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            return

        all_data: list[dict] = []
        page_size = 1000
        offset = 0

        while True:
            logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–ø–∏—Å–µ–π {offset + 1}-{offset + page_size}...")

            response = (
                supabase_client
                .table(table_name)
                .select("*")
                .order("id")
                .range(offset, offset + page_size - 1)
                .execute()
            )

            page_data = response.data or []
            if not page_data:
                break

            all_data.extend(page_data)
            offset += page_size

            if len(page_data) < page_size:
                break

            time.sleep(0.1)

        if not all_data:
            logger.warning("‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã.")
            return

        headers = list(all_data[0].keys())

        with Path(output_file).open("w", encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(
                f,
                fieldnames=headers,
                quoting=csv.QUOTE_ALL,
                escapechar="\\",
            )
            writer.writeheader()

            for row in all_data:
                safe_row = {
                    key: _serialize_value(value)
                    for key, value in row.items()
                }
                writer.writerow(safe_row)

        logger.info(f"‚úÖ –ë—ç–∫–∞–ø —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file} (—Å—Ç—Ä–æ–∫: {len(all_data)})")

    except Exception:
        logger.exception("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –±—ç–∫–∞–ø–∞")
        raise
